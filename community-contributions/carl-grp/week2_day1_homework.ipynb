{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87165b5d",
   "metadata": {},
   "source": [
    "# More advanced exercises\n",
    "\n",
    "Try creating a 3-way, perhaps bringing Gemini into the conversation! One student has completed this - see the implementation in the community-contributions folder.\n",
    "\n",
    "The most reliable way to do this involves thinking a bit differently about your prompts: just 1 system prompt and 1 user prompt each time, and in the user prompt list the full conversation so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f212f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6978cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set (and this is optional)\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:2]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set (and this is optional)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c005a068",
   "metadata": {},
   "outputs": [],
   "source": [
    "anthropic_url = \"https://api.anthropic.com/v1/\"\n",
    "gemini_url = \"https://generativelanguage.googleapis.com/v1beta/openai/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8656851f",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI()\n",
    "anthropic = OpenAI(api_key=anthropic_api_key, base_url=anthropic_url)\n",
    "gemini = OpenAI(api_key=google_api_key, base_url=gemini_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3b2dc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_model = \"gpt-4.1-mini\"\n",
    "claude_model = \"claude-3-5-haiku-latest\"\n",
    "gemini_model= \"gemini-2.5-pro\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe2c843",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = \"Blake: Hi\" + \"\\n\\nCharlie: Hey there\" \n",
    "print(conversation)\n",
    "\n",
    "import time\n",
    "import random\n",
    "\n",
    "# Define system prompts (these don't change)\n",
    "system_alex = \"\"\"\n",
    "You are Alex, a chatbot who is very argumentative; you disagree with anything in the conversation and you challenge everything, in a snarky way.\n",
    "You are in a conversation with Blake and Charlie.\n",
    "\"\"\"\n",
    "\n",
    "system_blake = \"\"\"\n",
    "You are Blake, a chatbot who is very shy but extremely smart; you try to deeply understand everything that has been that, and answer in a sharp, short and eloquent way.\n",
    "You are in a conversation with Alex and Charlie.\n",
    "\"\"\"\n",
    "\n",
    "system_charlie = \"\"\"\n",
    "You are Charlie, a chatbot who is not very smart but has a certain air of shrewdness; you try to emphasize practical aspects of the conversation that could be useful in daily life.\n",
    "You are in a conversation with Alex and Blake.\n",
    "\"\"\"\n",
    "\n",
    "def make_api_call_with_retry(client, model, messages, max_retries=3, name=\"\"):\n",
    "    \"\"\"Make API call with exponential backoff retry logic\"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = client.chat.completions.create(model=model, messages=messages)\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            if \"503\" in str(e) or \"overloaded\" in str(e).lower() or attempt < max_retries - 1:\n",
    "                wait_time = (2 ** attempt) + random.uniform(0, 1)  # Exponential backoff with jitter\n",
    "                print(f\"  {name} API error (attempt {attempt + 1}/{max_retries}): {str(e)[:100]}\")\n",
    "                print(f\"  Waiting {wait_time:.1f} seconds before retry...\")\n",
    "                time.sleep(wait_time)\n",
    "            else:\n",
    "                raise  # Re-raise if it's the last attempt and not a 503\n",
    "\n",
    "for i in range(1, 8):\n",
    "    print(f\"\\n--- Iteration {i} ---\")\n",
    "    \n",
    "    # Regenerate user prompts with updated conversation INSIDE the loop\n",
    "    user_alex = f\"\"\"\n",
    "You are Alex, in conversation with Blake and Charlie.\n",
    "The conversation so far is as follows:\n",
    "{conversation}\n",
    "Now with this, respond with what you would like to say next, as Alex.\n",
    "\"\"\"\n",
    "    \n",
    "    messages_alex = [{\"role\": \"system\", \"content\": system_alex}, {\"role\":\"user\", \"content\": user_alex}]\n",
    "    response_alex = make_api_call_with_retry(openai, gpt_model, messages_alex, name=\"Alex (OpenAI)\")\n",
    "    conversation += \"\\n\\nAlex:\" + response_alex.choices[0].message.content\n",
    "    print(\"\\n\\nAlex:\" + response_alex.choices[0].message.content)\n",
    "    time.sleep(2.0)  # Increased to 2 seconds between calls\n",
    "\n",
    "    # Regenerate user prompt for Blake\n",
    "    user_blake = f\"\"\"\n",
    "You are Blake, in conversation with Alex and Charlie.\n",
    "The conversation so far is as follows:\n",
    "{conversation}\n",
    "Now with this, respond with what you would like to say next, as Blake.\n",
    "\"\"\"\n",
    "    \n",
    "    messages_blake = [{\"role\": \"system\", \"content\": system_blake}, {\"role\":\"user\", \"content\": user_blake}]\n",
    "    response_blake = make_api_call_with_retry(anthropic, claude_model, messages_blake, name=\"Blake (Anthropic)\")\n",
    "    conversation += \"\\n\\nBlake:\" + response_blake.choices[0].message.content\n",
    "    print(\"\\n\\nBlake:\" + response_blake.choices[0].message.content)\n",
    "    time.sleep(2.0)  # Increased to 2 seconds\n",
    "\n",
    "    # Regenerate user prompt for Charlie\n",
    "    user_charlie = f\"\"\"\n",
    "You are Charlie, in conversation with Alex and Blake.\n",
    "The conversation so far is as follows:\n",
    "{conversation}\n",
    "Now with this, respond with what you would like to say next, as Charlie.\n",
    "\"\"\"\n",
    "    \n",
    "    messages_charlie = [{\"role\": \"system\", \"content\": system_charlie}, {\"role\":\"user\", \"content\": user_charlie}]\n",
    "    response_charlie = make_api_call_with_retry(gemini, gemini_model, messages_charlie, name=\"Charlie (Gemini)\")\n",
    "    conversation += \"\\n\\nCharlie:\" + response_charlie.choices[0].message.content\n",
    "    print(\"\\n\\nCharlie:\" + response_charlie.choices[0].message.content)\n",
    "    time.sleep(2.0)  # Increased to 2 seconds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
